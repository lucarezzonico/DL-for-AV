{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Evaluator.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"aEW8FsaTRaOo","executionInfo":{"status":"ok","timestamp":1649260856527,"user_tz":-120,"elapsed":8316,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}}},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","import torch.utils.data as utils\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import os\n","import platform\n","import pickle"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"bJAZFldDTQRz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649260872689,"user_tz":-120,"elapsed":16170,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}},"outputId":"1e8c0ca6-76ee-4932-882b-19c538af61a3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!rm -r DLAV-2022\n","!git clone https://github.com/vita-epfl/DLAV-2022.git\n","path = os.getcwd() + '/DLAV-2022/homeworks/hw2/test_batch'"],"metadata":{"id":"dtBf2_UXTPVs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649260876566,"user_tz":-120,"elapsed":3893,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}},"outputId":"6d9f81a3-1d3a-4b13-e7d5-129ade85aab8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove 'DLAV-2022': No such file or directory\n","Cloning into 'DLAV-2022'...\n","remote: Enumerating objects: 87, done.\u001b[K\n","remote: Counting objects: 100% (87/87), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 87 (delta 32), reused 65 (delta 17), pack-reused 0\u001b[K\n","Unpacking objects: 100% (87/87), done.\n"]}]},{"cell_type":"code","source":["# Set the variable to the location of the trained model\n","model_path = \"drive/MyDrive/Colab Notebooks/tp_3/ConvNN.ckpt\""],"metadata":{"id":"QB1xSP9nUZGQ","executionInfo":{"status":"ok","timestamp":1649260876567,"user_tz":-120,"elapsed":16,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class ConvNet(nn.Module):\n","    def __init__(self, n_input_channels=3, n_output=10):\n","        super().__init__()\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Define 2 or more different layers of the neural network                      #\n","        ################################################################################\n","        # size of input = [64 x 3 x 32 x 32]\n","        \n","        self.conv1 = nn.Conv2d(in_channels=n_input_channels, out_channels=32, kernel_size=5, stride=1, padding=0, dilation=1)  # w1 = (32 x 3 x 5 x 5), b1 = (32 x 1)\n","        self.bn1 = nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1)\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=0, dilation=1) # w2 = (64 x 32 x 5 x 5), b2 = (64 x 1)\n","        self.bn2 = nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1)\n","        self.fc1 = nn.Linear(in_features=64 * 5 * 5, out_features=1200)\n","        self.fc2 = nn.Linear(in_features=1200, out_features=n_output)\n","\n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","    \n","    def forward(self, x):\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Set up the forward pass that the input data will go through.                 #\n","        # A good activation function betweent the layers is a ReLu function.           #\n","        #                                                                              #\n","        # Note that the output of the last convolution layer should be flattened       #\n","        # before being inputted to the fully connected layer. We can flatten           #\n","        # Tensor `x` with `x.view`.                                                    #\n","        ################################################################################\n","\n","        # x = (64 x 3 x 32 x 32)\n","        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n","        x = self.bn1(x)\n","        # conv1 => x = (64 x 32 x 28 x 28), max_pool2d => x = (64 x 32 x 14 x 14), relu => x = (64 x 32 x 14 x 14)\n","        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n","        x = self.bn2(x)\n","        # conv2 => x = (64 x 64 x 10 x 10), max_pool2d => x = (64 x 64 x 5 x 5), relu => x = (64 x 64 x 5 x 5)\n","        x = F.relu(self.fc1(x.view(-1, 64 * 5 * 5)))\n","        # view => x = (64 x 1600), fc1 => x = (64 x 1200), relu => x = (64 x 1200)\n","        x = self.fc2(x)\n","        # fc2 => x = (64 x 10)\n","\n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","        \n","        return x\n","    \n","    def predict(self, x):\n","        logits = self.forward(x)\n","        return F.softmax(logits)"],"metadata":{"id":"QEIcPZ4hT7fY","executionInfo":{"status":"ok","timestamp":1649260876567,"user_tz":-120,"elapsed":14,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def predict_usingCNN(X):\n","    #########################################################################\n","    # TODO:                                                                 #\n","    # - Load your saved model                                               #\n","    # - Do the operation required to get the predictions                    #\n","    # - Return predictions in a numpy array                                 #\n","    # Note: For the predictions, you have to return the index of the max    #\n","    # value                                                                 #\n","    #########################################################################\n","    \n","    net = ConvNet(n_input_channels=3, n_output=10)    # define the network\n","    checkpoint = torch.load(model_path)\n","    net.load_state_dict(checkpoint) # Load the best computed parameters\n","\n","    print(net)  # net architecture\n","    \n","    outputs = net(X)    # don't use net.forward(X)  # X = [10'000 x 3 x 32 x 32]\n","    y_pred = torch.argmax(F.softmax(outputs).data, 1).numpy()\n","\n","    #########################################################################\n","    #                       END OF YOUR CODE                                #\n","    #########################################################################\n","    return y_pred\n","   "],"metadata":{"id":"p5v7OgpDR4m2","executionInfo":{"status":"ok","timestamp":1649260876568,"user_tz":-120,"elapsed":13,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["## Read DATA\n","def load_pickle(f):\n","    version = platform.python_version_tuple()\n","    if version[0] == '2':\n","        return  pickle.load(f)\n","    elif version[0] == '3':\n","        return  pickle.load(f, encoding='latin1')\n","    raise ValueError(\"invalid python version: {}\".format(version))\n","\n","def load_CIFAR_batch(filename):\n","  \"\"\" load single batch of cifar \"\"\"\n","  with open(filename, 'rb') as f:\n","    datadict = load_pickle(f)\n","    X = datadict['data']\n","    Y = datadict['labels']\n","    X = X.reshape(10000, 3, 32, 32).astype(\"float\")\n","    Y = np.array(Y)\n","    return X, Y\n","test_filename = path\n","X,Y = load_CIFAR_batch(test_filename)"],"metadata":{"id":"IGqVw4U3Sy21","executionInfo":{"status":"ok","timestamp":1649260876939,"user_tz":-120,"elapsed":382,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Data Manipulation\n","mean_pytorch = np.array([0.4914, 0.4822, 0.4465])\n","std_pytorch = np.array([0.2023, 0.1994, 0.2010])\n","X_pytorch = np.divide(np.subtract( X/255 , mean_pytorch[np.newaxis, :,np.newaxis,np.newaxis]), std_pytorch[np.newaxis, :,np.newaxis,np.newaxis])\n","\n","# Run Prediction and Evaluation\n","prediction_cnn = predict_usingCNN(torch.from_numpy(X_pytorch).float())\n","acc_cnn = sum(prediction_cnn == Y)/len(X_pytorch)\n","print(\"CNN Accuracy= %f\"%(acc_cnn))"],"metadata":{"id":"qiRBbv7fR-DB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ced9408-182e-4c31-deb0-74274283364f","executionInfo":{"status":"ok","timestamp":1649260885721,"user_tz":-120,"elapsed":8786,"user":{"displayName":"Luca Rezzonico","userId":"13659644689464206961"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ConvNet(\n","  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=1600, out_features=1200, bias=True)\n","  (fc2): Linear(in_features=1200, out_features=10, bias=True)\n",")\n","CNN Accuracy= 0.792900\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]}]}]}